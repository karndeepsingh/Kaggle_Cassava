{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "98WZ-kg3TDXP",
        "lxXiYgW0TDXR",
        "xk90ypd_TDXS"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPgoWbnFyhlp",
        "outputId": "8a27de51-4267-4a20-a151-9ed840b7aa93"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Oxq0OqY-TDW_"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "import keras\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Defining the working directories\n",
        "\n",
        "work_dir = '/content/drive/MyDrive/KaggleCassava/'\n",
        "os.listdir(work_dir) \n",
        "train_path = '/content/drive/MyDrive/KaggleCassava/train_images_new'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgGvZtKQp-fo"
      },
      "source": [
        "# !unzip -u \"/content/drive/MyDrive/KaggleCassava/train_images.zip\" -d \"/content/drive/MyDrive/KaggleCassava/train_images_new\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XOFDksWhcr"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sxhT73BB-AP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "1q_WZtyeVHHZ",
        "outputId": "889d03a9-8bfe-4843-89d3-03d9f0fa54d9"
      },
      "source": [
        "data = pd.read_csv(work_dir + 'train_folds_cassava.csv')\r\n",
        "data.drop(\"image_path\",axis=1,inplace=True)\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2706759956.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2720713385.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>403458333.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4002244325.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1370253627.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label  kfold\n",
              "0  2706759956.jpg      2      0\n",
              "1  2720713385.jpg      3      0\n",
              "2   403458333.jpg      1      0\n",
              "3  4002244325.jpg      3      0\n",
              "4  1370253627.jpg      3      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "dUPBZxbKTDXK"
      },
      "source": [
        "# Read data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5KNS8xmGTDXK"
      },
      "source": [
        "f = open(work_dir + 'label_num_to_disease_map.json')\n",
        "real_labels = json.load(f)\n",
        "real_labels = {int(k):v for k,v in real_labels.items()}\n",
        "\n",
        "# Defining the working dataset\n",
        "data['class_name'] = data.label.map(real_labels)\n",
        "\n",
        "# Spliting the data  as we are doing folds 18/1\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train,val = train_test_split(data, test_size = 0.05, random_state = 42, stratify = data['class_name'])\n",
        "\n",
        "# Importing the data using ImageDataGenerator\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = 512 #456\n",
        "size = (IMG_SIZE,IMG_SIZE)\n",
        "n_CLASS = 5\n",
        "BATCH_SIZE = 15\n",
        "\n",
        "datagen_train = ImageDataGenerator(\n",
        "                    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    rotation_range = 40,\n",
        "                    width_shift_range = 0.2,\n",
        "                    height_shift_range = 0.2,\n",
        "                    shear_range = 0.2,\n",
        "                    zoom_range = 0.2,\n",
        "                    horizontal_flip = True,\n",
        "                    vertical_flip = True,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "datagen_val = ImageDataGenerator(\n",
        "                    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    )\n",
        "\n",
        "def generate_train_val(train, train_path, val):\n",
        "  train_set = datagen_train.flow_from_dataframe(train,\n",
        "                               directory = train_path,\n",
        "                               seed=42,\n",
        "                               x_col = 'image_id',\n",
        "                               y_col = 'class_name',\n",
        "                               target_size = size,\n",
        "                                #color_mode=\"rgb\",\n",
        "                               class_mode = 'categorical',\n",
        "                               interpolation = 'nearest',\n",
        "                               shuffle = True,\n",
        "                               batch_size = BATCH_SIZE)\n",
        "\n",
        "  val_set = datagen_val.flow_from_dataframe(val,\n",
        "                               directory = train_path,\n",
        "                               seed=42,\n",
        "                               x_col = 'image_id',\n",
        "                               y_col = 'class_name',\n",
        "                               target_size = size,\n",
        "                               #color_mode=\"rgb\",\n",
        "                               class_mode = 'categorical',\n",
        "                               interpolation = 'nearest',\n",
        "                               shuffle = True,\n",
        "                               batch_size = BATCH_SIZE)\n",
        "  return train_set, val_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Ul4lNlMyTDXL",
        "outputId": "1effa5b4-69f3-4455-f681-66ab196cc87b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB3, EfficientNetB4\n",
        "\n",
        "def create_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    # initialize the model with input shape\n",
        "    model.add(EfficientNetB4(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False,\n",
        "                             weights = 'imagenet',\n",
        "                             drop_connect_rate=0.6))\n",
        "    #for layer in model.layers[:-40]:  # Training just part of the architecture do not optimize the performance\n",
        "    #    layer.trainable = False\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(n_CLASS, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "leaf_model = create_model()\n",
        "leaf_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-05d87a9ec8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mleaf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mleaf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-05d87a9ec8a5>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#for layer in model.layers[:-40]:  # Training just part of the architecture do not optimize the performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#    layer.trainable = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1L2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2685\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer global_average_pooling2d_8 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1792)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oaZkEmyGTDXM"
      },
      "source": [
        "EPOCHS = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEvWB-ogl_cK"
      },
      "source": [
        "def symmetric_cross_entropy(alpha, beta):\r\n",
        "    def loss(y_true, y_pred):\r\n",
        "        y_true_1 = y_true\r\n",
        "        y_pred_1 = y_pred\r\n",
        "\r\n",
        "        y_true_2 = y_true\r\n",
        "        y_pred_2 = y_pred\r\n",
        "\r\n",
        "        y_pred_1 = tf.clip_by_value(y_pred_1, 1e-7, 1.0)\r\n",
        "        y_true_2 = tf.clip_by_value(y_true_2, 1e-4, 1.0)\r\n",
        "\r\n",
        "        return alpha*tf.math.reduce_mean(-tf.math.reduce_sum(y_true_1 * tf.math.log(y_pred_1), axis = -1)) + beta*tf.math.reduce_mean(-tf.math.reduce_sum(y_pred_2 * tf.math.log(y_true_2), axis = -1))\r\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fJ8RELtuTDXM"
      },
      "source": [
        "def Model_fit(k):\n",
        "    \n",
        "    #leaf_model = None\n",
        "    \n",
        "    leaf_model = create_model()\n",
        "    '''Compiling the model'''\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False,\n",
        "                                                   label_smoothing=0.0001,\n",
        "                                                   name='categorical_crossentropy' )\n",
        "    \n",
        "    leaf_model.compile(optimizer = Adam(learning_rate = 1e-3),\n",
        "                        loss = loss, #'categorical_crossentropy'\n",
        "                        metrics = ['categorical_accuracy']) #'acc'\n",
        "    \n",
        "    # Stop training when the val_loss has stopped decreasing for 3 epochs.\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=3,\n",
        "                       restore_best_weights=True, verbose=1)\n",
        "    \n",
        "    # Save the model with the minimum validation loss\n",
        "    checkpoint_cb = ModelCheckpoint(f\"{work_dir}/Cassava_best_model_fold{k}.h5\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor = 'val_loss',\n",
        "                                    mode='min')\n",
        "    \n",
        "    # reduce learning rate\n",
        "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                                  factor = 0.2,\n",
        "                                  patience = 2,\n",
        "                                  min_lr = 1e-6,\n",
        "                                  mode = 'min',\n",
        "                                  verbose = 1)\n",
        "    \n",
        "    # with Folds as of 18/1\n",
        "    train = data[data['kfold'] != k]\n",
        "    val = data[data['kfold'] == k]\n",
        "    train.drop('kfold',axis=1,inplace=True)\n",
        "    val.drop('kfold',axis=1,inplace=True)\n",
        "\n",
        "    train_set, val_set = generate_train_val(train, train_path, val)\n",
        "    STEP_SIZE_TRAIN = train_set.n//train_set.batch_size\n",
        "    STEP_SIZE_VALID = val_set.n//val_set.batch_size\n",
        "\n",
        "    # history fit\n",
        "    history = leaf_model.fit(train_set,\n",
        "                             validation_data = val_set,\n",
        "                             epochs= EPOCHS,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             #class_weight = d_class_weights,\n",
        "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                             validation_steps = STEP_SIZE_VALID,\n",
        "                             callbacks=[es, checkpoint_cb, reduce_lr])\n",
        "    \n",
        "    leaf_model.save(f'Cassava_model_fold{k}'+'.h5')  \n",
        "    \n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC4GZ9kRXJuB",
        "outputId": "80fd4530-27b4-4856-92eb-4d6f0f18ffbe"
      },
      "source": [
        "data['kfold'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "GeLKvECyTDXM",
        "outputId": "ac9a9c8d-7528-47d6-a3b8-5d4ea14c6c94"
      },
      "source": [
        "#run from fold 4 onwards on 26/1\r\n",
        "for fold in range(0,5):\r\n",
        "  results = Model_fit(fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 17117 validated image filenames belonging to 5 classes.\n",
            "Found 4280 validated image filenames belonging to 5 classes.\n",
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-41d7c6a9c5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#run from fold 4 onwards on 26/1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-1d9d5b421d11>\u001b[0m in \u001b[0;36mModel_fit\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     49\u001b[0m                              \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                              callbacks=[es, checkpoint_cb, reduce_lr])\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mleaf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Cassava_model_fold{k}'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[960] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_7/efficientnetb4/block5b_bn/FusedBatchNormV3 (defined at <ipython-input-24-1d9d5b421d11>:51) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_109659]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P28R2klATDXN"
      },
      "source": [
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mMky2jNTDXN"
      },
      "source": [
        "# Albumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EJyOrRdFTDXO"
      },
      "source": [
        "!pip install git+https://github.com/mjkvaak/ImageDataAugmentor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FG2vqg05TDXO"
      },
      "source": [
        "image_size = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0DYS2fF2TDXO"
      },
      "source": [
        "from ImageDataAugmentor.image_data_augmentor import *\n",
        "import albumentations as A\n",
        "\n",
        "train_augmentations = A.Compose([\n",
        "            A.RandomCrop(image_size, image_size, p=1),\n",
        "            A.CoarseDropout(p=0.5),\n",
        "            A.Cutout(p=0.5),\n",
        "            A.Flip(p=0.5),\n",
        "            A.ShiftScaleRotate(p=0.5),\n",
        "            A.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
        "            A.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2)),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            A.ToFloat()\n",
        "            ], p=1)\n",
        "\n",
        "val_augmentations = A.Compose([\n",
        "                A.CenterCrop(image_size, image_size, p=1),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "                A.ToFloat()\n",
        "                ], p=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZTPpRRJGTDXP"
      },
      "source": [
        "input_shape = (image_size, image_size, 3)\n",
        "target_size = (image_size, image_size)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jv7O6NTdTDXP"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xbQSHgalTDXP"
      },
      "source": [
        "def TFDataGenerator(train_set, val_set):\n",
        "    \n",
        "    train_generator = ImageDataAugmentor(augment=train_augmentations,featurewise_center=True, featurewise_std_normalization=True)\n",
        "    val_generator = ImageDataAugmentor(augment=val_augmentations,featurewise_center=True, featurewise_std_normalization=True)\n",
        "    \n",
        "    train_datagen = train_generator.flow_from_dataframe(\n",
        "                  preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "                  dataframe = train_set,\n",
        "                  directory='../input/cassava-leaf-disease-classification/train_images',\n",
        "                  x_col='image_id',\n",
        "                  y_col='label',\n",
        "                  target_size=target_size,\n",
        "                  batch_size=batch_size,\n",
        "                  shuffle=True,\n",
        "                  class_mode='categorical',\n",
        "                  seed=88)\n",
        "\n",
        "    val_datagen = val_generator.flow_from_dataframe(\n",
        "                preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "                dataframe = val_set,\n",
        "                directory='../input/cassava-leaf-disease-classification/train_images',\n",
        "                x_col='image_id',\n",
        "                y_col='label',\n",
        "                target_size=target_size,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                class_mode='categorical',\n",
        "                seed=88)\n",
        "    \n",
        "    return train_datagen, val_datagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98WZ-kg3TDXP"
      },
      "source": [
        "# EfficientNet and InceptionNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CBgqu7PaTDXQ"
      },
      "source": [
        "!wget https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UB0DY24zTDXQ"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oSf6JJp-TDXQ"
      },
      "source": [
        "def create_Inception():\n",
        "    base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
        "\n",
        "    # Rebuild top\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    model = base_model(inputs)\n",
        "    pooling = GlobalAveragePooling2D()(model)\n",
        "    dropout = Dropout(0.2)(pooling)\n",
        "\n",
        "    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n",
        "\n",
        "    # Compile\n",
        "    inception = Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "    loss = CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n",
        "\n",
        "    inception.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "    return inception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m6RKEJKLTDXQ"
      },
      "source": [
        "def create_EffnetB3():\n",
        "    base_model = EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=input_shape, drop_connect_rate=0.6)\n",
        "\n",
        "    # Rebuild top\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    model = base_model(inputs)\n",
        "    gpool = GlobalAveragePooling2D()(model)\n",
        "    flat = Flatten()(gpool)\n",
        "    dense = Dense(256, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001))(flat)\n",
        "    drop = Dropout(0.5)(dense)\n",
        "    outputs = Dense(5, activation = \"softmax\", dtype='float32')(drop)\n",
        "#     model.add(Dense(256, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Dense(n_CLASS, activation = 'softmax'))\n",
        "#     pooling = GlobalAveragePooling2D()(model)\n",
        "#     dropout = Dropout(0.2)(pooling)\n",
        "\n",
        "#    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n",
        "\n",
        "    # Compile\n",
        "    efficientnet = Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "    loss = CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n",
        "\n",
        "    efficientnet.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "    return efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxXiYgW0TDXR"
      },
      "source": [
        "# Model run with folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f4ANlt3ATDXR"
      },
      "source": [
        "epochs = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SoEXmJdpTDXR"
      },
      "source": [
        "def run_efficientnet(fold, df):\n",
        "    train_set = df[df['kfold'] != fold]\n",
        "    valid_set = df[df['kfold'] == fold]\n",
        "    train_datagen, val_datagen = TFDataGenerator(train_set, valid_set)\n",
        "    model = create_EffnetB3()\n",
        "    \n",
        "    model_name = \"efficientnet\"\n",
        "    fold_name = \"fold.h5\"\n",
        "    filepath = model_name + str(fold+1) + fold_name\n",
        "    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n",
        "                 EarlyStopping(monitor='val_loss', patience=3),\n",
        "                 ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n",
        "    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n",
        "    return 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8WSQk2aRTDXR"
      },
      "source": [
        "def run_inceptionnet(fold, df):\n",
        "    train_set = df[df['kfold'] != fold]\n",
        "    valid_set = df[df['kfold'] == fold]\n",
        "    train_datagen, val_datagen = TFDataGenerator(train_set, valid_set)\n",
        "    model = create_Inception()\n",
        "    \n",
        "    model_name = \"inceptionnet\"\n",
        "    fold_name = \"fold.h5\"\n",
        "    filepath = model_name + str(fold+1) + fold_name\n",
        "    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n",
        "                 EarlyStopping(monitor='val_loss', patience=3),\n",
        "                 ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n",
        "    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n",
        "    return 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FSD2oACZTDXR"
      },
      "source": [
        "for fold in range(5):\n",
        "    print(f\"Training fold {fold}\")\n",
        "    run_efficientnet(fold, df)\n",
        "\n",
        "for fold in range(5):\n",
        "    print(f\"Training fold {fold}\")\n",
        "    run_inceptionnet(fold, df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "xk90ypd_TDXS"
      },
      "source": [
        "# Inferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fKjqyPxzTDXS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CTE0ww0pTDXS"
      },
      "source": [
        "weight_path = '../input/ensemblescassava'\n",
        "my_model_list = os.listdir(weight_path)\n",
        "models = []\n",
        "for my_model in my_model_list:\n",
        "    models.append(load_model(weight_path+\"/\"+my_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lbPUk7A1TDXS"
      },
      "source": [
        "SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YqvO3vGWTDXS"
      },
      "source": [
        "my_model_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GKZP2_f4TDXS"
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wmr1eQMoTDXT"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "92EPiDC3TDXT"
      },
      "source": [
        "os.chdir(\"../input/imagedataaugmentor/ImageDataAugmentor-master\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fUbCj3U6TDXT"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2ce5VAxaTDXT"
      },
      "source": [
        "from ImageDataAugmentor.image_data_augmentor import *\n",
        "import albumentations as A\n",
        "\n",
        "image_size = 300\n",
        "input_shape = (image_size, image_size, 3)\n",
        "target_size = (image_size, image_size)\n",
        "batch_size = 16\n",
        "\n",
        "test_augmentations = A.Compose([\n",
        "            A.RandomCrop(image_size, image_size, p=1),\n",
        "            A.CoarseDropout(p=0.5),\n",
        "            A.Cutout(p=0.5),\n",
        "            A.Flip(p=0.5),\n",
        "            A.ShiftScaleRotate(p=0.5),\n",
        "            A.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
        "            A.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2)),\n",
        "            A.ToFloat()\n",
        "            ], p=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def TFDataGenerator(test_set):\n",
        "    \n",
        "    test_generator = ImageDataAugmentor(augment=test_augmentations)\n",
        "    \n",
        "    test_datagen = test_generator.flow_from_dataframe(\n",
        "                  dataframe = test_set,\n",
        "                  x_col='path',\n",
        "                  y_col = None,\n",
        "                  class_mode = None,\n",
        "                  target_size=target_size,\n",
        "                  batch_size=batch_size,\n",
        "                  shuffle=False)\n",
        "    \n",
        "    return test_datagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ogh_wEFETDXT"
      },
      "source": [
        "INPUT_DIR = '/kaggle/input/cassava-leaf-disease-classification/'\n",
        "TEST_IMAGE_DIR = INPUT_DIR + 'test_images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bEa7G0NyTDXT"
      },
      "source": [
        "import glob\n",
        "TEST_IMAGES = TEST_IMAGE_DIR + '/*.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MAYtg8WLTDXU"
      },
      "source": [
        "def create_df():\n",
        "    test_images = glob.glob(TEST_IMAGES)\n",
        "    test = pd.DataFrame(test_images, columns = ['path'])\n",
        "    return test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t8t5MF1lTDXU"
      },
      "source": [
        "test_set = create_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WeMBTZdeTDXU"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B0MkeNPfTDXU"
      },
      "source": [
        "test_data = TFDataGenerator(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RCoRAOGgTDXU"
      },
      "source": [
        "def predict_test(test_data, model):\n",
        "    count = 3\n",
        "    predictions = []\n",
        "    for i in range(count):\n",
        "        preds = model.predict_generator(test_data)\n",
        "        predictions.append(preds)\n",
        "    predictions = np.mean(predictions, axis=0)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UN6m8O-XTDXU"
      },
      "source": [
        "preds = []\n",
        "for model in models:\n",
        "    preds.append(predict_test(test_data, model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D-HBlE6ETDXV"
      },
      "source": [
        "np.mean(preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8etvtPCDTDXV"
      },
      "source": [
        "mean_pred = np.mean(preds, axis=0)\n",
        "mean_pred = np.argmax(mean_pred, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FxoKaoOMTDXV"
      },
      "source": [
        "mean_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jKr1lqDpTDXV"
      },
      "source": [
        "test_set['image_id'] = test_set['path'].apply(lambda x: x.split('/')[-1])\n",
        "test_set['label'] = mean_pred\n",
        "test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0KgjqdjqTDXV"
      },
      "source": [
        "os.chdir(\"../../../working\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QX0sxy1MTDXV"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kKXPjd9cTDXV"
      },
      "source": [
        "test_set[['image_id','label']].to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G50K-CWSTDXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}